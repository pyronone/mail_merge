[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mail_merge",
    "section": "",
    "text": "In 2+ years at TELUS Health / LifeWorks, I have successfully executed over a dozen mail merges, many of which had thousands of recipients, a wide variety of templates, tight deadlines, and constant changes to both templates and data.\nWith a natural inclination for process efficiency, I used Python scripts to streamline the process. For the sake of organization, maintainability, and documentation, I have bundled commonly used functions from those scripts into a single package. I have also tested, with great results, using docxtpl for the actual merge itself as the built-in MS Word function proved inconsistent and unreliable, especially for larger merges and complex templates.\nThis package allows for effortless running and re-running of merges with manual steps kept to a minimum. This is particularly useful when there are frequent changes to the templates and/or data, and when there are many different groups requiring different combinations of templates.\nDocumentation",
    "crumbs": [
      "mail_merge"
    ]
  },
  {
    "objectID": "merge.html",
    "href": "merge.html",
    "title": "01_merge",
    "section": "",
    "text": "00 sample cfg\n\nsource\n\ncreate_sample_cfg\n\n create_sample_cfg (_fn:str='cfg.yml')\n\ncreate sample cfg file in cwd\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\n_fn\nstr\ncfg.yml\nstr\n\n\nReturns\nNone\n\n\n\n\n\nThe config file uses YAML format for easy editing. Here you specify the data / template filepaths, as well as which groups require which templates. For example:\ndata: C:\\Users\\Ron\\Downloads\\CODE\\mail_merge\\tests2\\clean_dat2.parquet\ngroups:\n- group1:\n  - C:\\Users\\Ron\\Downloads\\CODE\\mail_merge\\tests2\\tpls\\sample_tpl.docx\n  - C:\\Users\\Ron\\Downloads\\CODE\\mail_merge\\tests2\\tpls\\sample_tpl2.docx\n- group2:\n  - C:\\Users\\Ron\\Downloads\\CODE\\mail_merge\\tests2\\tpls\\sample_tpl.docx\nThis is particularly useful when you have many groups, each requiring different (combinations of) templates.\n\n\n\n01 merge\n\nsource\n\nmerge\n\n merge (cfg_path:str, id_col:str, group_col:str,\n        multi_line_cols:list=['str_mailing_details'], _tbls:list=None,\n        _test:bool=False)\n\nRun merge\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncfg_path\nstr\n\npath to config yaml file\n\n\nid_col\nstr\n\nname of unique id column\n\n\ngroup_col\nstr\n\nname of column w/ group identifier\n\n\nmulti_line_cols\nlist\n[‘str_mailing_details’]\nOnly needed if multi-line outputs are bugged. Add all columns w/ newline character.\n\n\n_tbls\nlist\nNone\ncorresponds to table name(s) in template\n\n\n_test\nbool\nFalse\nif True, only processes first 5 for quick checking/iteration\n\n\nReturns\nNone\n\n\n\n\n\nUsing the example config above, the example result looks something like this:\n\n\n\n\nActual sample files can be found here: https://github.com/pyronone/mail_merge/tree/main/tests2",
    "crumbs": [
      "01_merge"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "00_core",
    "section": "",
    "text": "00 init fxs\n\nsource\n\nyaml_helper\n\n yaml_helper (fpath:str='./config.yaml', mode:str='r', data:dict=None)\n\nHelper function to read, write, append to files in yaml format. Checks for duplicate keys if reading or appending.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfpath\nstr\n./config.yaml\nstr\n\n\nmode\nstr\nr\nstr - r / a / w\n\n\ndata\ndict\nNone\ndict - cannot be None if writing or appending\n\n\nReturns\ndict\n\ndict - data if reading, {‘r’: 0} if writing/appending\n\n\n\n\nsource\n\n\nfp\n\n fp (relative_fp:str, base_dir:str='.')\n\nFor referencing filepaths relative to pkg dir.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrelative_fp\nstr\n\nstr - eg. “../dir/file.txt”\n\n\nbase_dir\nstr\n.\nstr\n\n\nReturns\nstr\n\nstr\n\n\n\n\n\n\n01 format numbers\n\nsource\n\nFormatOptions\n\n FormatOptions (format:bool=True, prefix:str='', suffix:str='',\n                comma:bool=True, comma_str:str=',',\n                pad_zeroes_at_end:bool=True,\n                return_int_if_possible:bool=False, decimal_str:str='.')\n\nOptions for numerical formatting (options for any/all locale conventions / currency formatting).\n\n\nCode\n# * DOC\nFormatOptions()\n\n\nFormatOptions(format=True, prefix='', suffix='', comma=True, comma_str=',', pad_zeroes_at_end=True, return_int_if_possible=False, decimal_str='.')\n\n\n\nsource\n\n\nfix_round_and_format\n\n fix_round_and_format (num:float, position:int,\n                       format_opts:__main__.FormatOptions)\n\ndeprecated - use round_and_format\n\n\n\n\nType\nDetails\n\n\n\n\nnum\nfloat\nfloat\n\n\nposition\nint\nint\n\n\nformat_opts\nFormatOptions\nFormatOptions\n\n\nReturns\ntyping.Union[str, float]\nUnion[str, float]\n\n\n\n\n\nCode\n# * TEST\nassert fix_round_and_format(123.445, 2, FormatOptions()) == \"123.45\"\nassert fix_round_and_format(9123.445, 2, FormatOptions(comma=True)) == \"9,123.45\"\nassert fix_round_and_format(2123.445, 2, FormatOptions(comma=False)) == \"2123.45\"\nassert (\n    fix_round_and_format(123.445, 4, FormatOptions(comma=False, pad_zeroes_at_end=True))\n    == \"123.4450\"\n)\nassert fix_round_and_format(-2342.475, 2, FormatOptions()) == \"-2,342.48\"\n\nassert (\n    fix_round_and_format(2342.999, 0, FormatOptions(return_int_if_possible=True))\n    == \"2,343\"\n)\nassert (\n    fix_round_and_format(2342.999, 0, FormatOptions(return_int_if_possible=False))\n    == \"2,343.0\"\n)\nassert (\n    fix_round_and_format(\n        2342.999, 0, FormatOptions(return_int_if_possible=False, comma=False)\n    )\n    == \"2343.0\"\n)\nassert fix_round_and_format(2342.999, 0, FormatOptions(comma=False)) == \"2343.0\"\n\nassert (\n    fix_round_and_format(2342.999, 1, FormatOptions(return_int_if_possible=True))\n    == \"2,343\"\n)\nassert (\n    fix_round_and_format(\n        2342.999, 1, FormatOptions(return_int_if_possible=True, comma=False)\n    )\n    == \"2343\"\n)\nassert (\n    fix_round_and_format(2342.999, 1, FormatOptions(return_int_if_possible=False))\n    == \"2,343.0\"\n)\n\nassert fix_round_and_format(0.0, 0, FormatOptions()) == \"0.0\"\nassert fix_round_and_format(\"0\", 0, FormatOptions()) == \"0\"\nassert fix_round_and_format(\"abc\", 0, FormatOptions()) == \"abc\"\nassert fix_round_and_format(\"str\", 0, FormatOptions()) == \"str\"\n\nassert pd.isnull(fix_round_and_format(np.nan, 2, FormatOptions()))\n\n\n\n\nCode\n# * DOC\nround(123.445, 2)\n\n\n123.44\n\n\n\n\nCode\n# * DOC\nfix_round_and_format(123.445, 2, FormatOptions())\n\n\n'123.45'\n\n\n\n\nCode\n# * DOC\nfix_round_and_format(123.445, 2, FormatOptions(prefix=\"$\"))\n\n\n'$123.45'\n\n\n\n\nCode\n# * DOC\nfix_round_and_format(123.445, 2, FormatOptions(suffix=\"$\"))\n\n\n'123.45$'\n\n\n\n\nCode\n# * DOC\nfix_round_and_format(9123.445, 2, FormatOptions(suffix=\"$\", comma_str=\" \"))\n\n\n'9 123.45$'\n\n\n\n\nCode\n# * DOC\nfix_round_and_format(\n    9123.445, 2, FormatOptions(suffix=\"$\", comma_str=\".\", decimal_str=\",\")\n)\n\n\n'9.123,45$'\n\n\n\nsource\n\n\nround_and_format\n\n round_and_format (num:float, position:int,\n                   format_opts:__main__.FormatOptions)\n\n…\n\n\n\n\nType\nDetails\n\n\n\n\nnum\nfloat\nfloat\n\n\nposition\nint\nint\n\n\nformat_opts\nFormatOptions\nFormatOptions\n\n\nReturns\ntyping.Union[str, float]\nUnion[str, float]\n\n\n\n\n\n\n02 format dates\n\nsource\n\ndate_to_string\n\n date_to_string\n                 (t_val:Union[pandas._libs.tslibs.timestamps.Timestamp,dat\n                 etime.datetime], long:bool=True, period:bool=False)\n\n…\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nt_val\ntyping.Union[pandas._libs.tslibs.timestamps.Timestamp, datetime.datetime]\n\nUnion[pd.Timestamp, datetime]\n\n\nlong\nbool\nTrue\nbool\n\n\nperiod\nbool\nFalse\nbool\n\n\nReturns\nstr\n\nstr\n\n\n\n\n\nCode\n# * TEST\nx = datetime(2024, 3, 19, 16, 39, 2, 126548)\nassert date_to_string(x) == \"March 19, 2024\"\nassert date_to_string(x, long=False) == \"Mar 19, 2024\"\nassert date_to_string(x, period=True, long=False) == \"Mar. 19, 2024\"\n\n\n\nsource\n\n\nconvert_excel_date\n\n convert_excel_date (ordinal:Union[int,float])\n\n…\n\n\n\n\nType\nDetails\n\n\n\n\nordinal\ntyping.Union[int, float]\nfloat - eg. 45292\n\n\nReturns\ndatetime\ndatetime\n\n\n\n\n\nCode\n# * TEST\nassert convert_excel_date(0) == datetime(1899, 12, 31, 0, 0)\nassert convert_excel_date(2) == datetime(1900, 1, 2, 0, 0)\nassert convert_excel_date(45292) == datetime(2024, 1, 1, 0, 0)\nassert convert_excel_date(45292.0) == datetime(2024, 1, 1, 0, 0)\nassert convert_excel_date(45292.25) == datetime(2024, 1, 1, 6, 0)\n\n\n\nsource\n\n\ndate_to_french\n\n date_to_french (date_obj:Union[pandas._libs.tslibs.timestamps.Timestamp,d\n                 atetime.datetime], long:bool=True)\n\n…\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndate_obj\ntyping.Union[pandas._libs.tslibs.timestamps.Timestamp, datetime.datetime]\n\nUnion[pd.Timestamp, datetime]\n\n\nlong\nbool\nTrue\nbool\n\n\nReturns\nstr\n\nstr\n\n\n\n\n\nCode\n# * TEST\nassert date_to_french(datetime(1899, 12, 31, 0, 0)) == \"31 décembre 1899\"\nassert date_to_french(datetime(1899, 12, 31, 0, 0), long=False) == \"31 déc. 1899\"\n\n\n\nsource\n\n\nconvert_yyyymmdd\n\n convert_yyyymmdd (date_str:str)\n\n…\n\n\n\n\nType\nDetails\n\n\n\n\ndate_str\nstr\nstr - eg. 19810123\n\n\nReturns\nTimestamp\npd.Timestamp\n\n\n\n\n\nCode\n# * TEST\nassert convert_yyyymmdd(\"19120124\") == pd.Timestamp(\"1912-01-24 00:00:00\")\n\n\n\n\n\n03 format addresses\n\nsource\n\nadd_mailing_details_col\n\n add_mailing_details_col (df:pandas.core.frame.DataFrame,\n                          address_dict:dict,\n                          col_name:str='str_mailing_details')\n\nAdds column to dataframe w/ full mailing details in upper case: full name, street(s), city / province/state / postal code (handles all combinations in case of foreign addresses), country. If there’s a c/o line, moves it to 2nd line.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\npd.DataFrame\n\n\naddress_dict\ndict\n\ndict - see docs for example\n\n\ncol_name\nstr\nstr_mailing_details\nstr - name of column that will be added\n\n\nReturns\nDataFrame\n\npd.DataFrame\n\n\n\n\n\nCode\n# * DOC\ndf = pd.read_excel(\"../tests/for_docs/fake_data.xlsx\")\ndf\n\n\n\n\n\n\n\n\n\nid\nfname\nlname\ndob\ndob_verified\nemail\nphone\n_full_name\nstreet1\nstreet2\ncity\nprovince\npostal_code\ncountry\ncomment\namt\nrand_int\n\n\n\n\n0\n5790492\nHenry\nAlvarado\n1940-01-10\nTrue\nmbrown@example.org\n(465) 529-2322\nHenry Alvarado\n91971 Williams Shoals\nc/o James Smith\nPort Richard\nSK\nM6J 1P4\nCanada\nTenetur hic eaque praesentium.\n74068.20\n4582\n\n\n1\n5266792\nRobert\nHenry\n1996-02-04\nTrue\ngonzalesmegan@example.com\n812-671-2491\nRobert Henry\n54198 Lambert Isle\nUnit 5\nStevensstad\nNU\nM2M 3L2\nCanada\nVoluptatibus fugit nam repellendus nemo repell...\n324.62\n5486\n\n\n2\n3735642\nJennifer\nRoss\n2004-04-27\nTrue\nhernandezjill@example.org\n1-156-761-3895\nJennifer Ross\n10535 Bartlett Hills\nNaN\nMcknightchester\nMB\nT8K 6J5\nCanada\nTemporibus eaque quis dignissimos reiciendis d...\n9770.60\n9002\n\n\n\n\n\n\n\n\n\nCode\n# * DOC\n# Example address_dict, where values are the column names in the data. Assumes a maximum of three columns for street.\naddress_dict = {\n    \"name\": \"_full_name\",\n    \"street1\": \"street1\",\n    \"street2\": \"street2\",\n    \"street3\": \"n/a\",\n    \"city\": \"city\",\n    \"prov\": \"province\",\n    \"pc\": \"postal_code\",\n    \"country\": \"country\",\n}\ndf = add_mailing_details_col(df, address_dict, \"str_mailing_details\")\ndf[[\"str_mailing_details\"]]\n\n\n\n\n\n\n\n\n\nstr_mailing_details\n\n\n\n\n0\nHENRY ALVARADO\\nC/O JAMES SMITH\\n91971 WILLIAM...\n\n\n1\nROBERT HENRY\\n54198 LAMBERT ISLE\\nUNIT 5\\nSTEV...\n\n\n2\nJENNIFER ROSS\\n10535 BARTLETT HILLS\\nMCKNIGHTC...\n\n\n\n\n\n\n\n\n\nCode\n# * DOC\nfor res in df[\"str_mailing_details\"].tolist():\n    print(res, \"\\n\")\n\n\nHENRY ALVARADO\nC/O JAMES SMITH\n91971 WILLIAMS SHOALS\nPORT RICHARD, SK  M6J 1P4\nCANADA \n\nROBERT HENRY\n54198 LAMBERT ISLE\nUNIT 5\nSTEVENSSTAD, NU  M2M 3L2\nCANADA \n\nJENNIFER ROSS\n10535 BARTLETT HILLS\nMCKNIGHTCHESTER, MB  T8K 6J5\nCANADA \n\n\n\n\nsource\n\n\nprovince_abbrev\n\n province_abbrev (province_name:str, errors:str='raise')\n\n…\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nprovince_name\nstr\n\nstr\n\n\nerrors\nstr\nraise\nstr - raise / coerce (if no match, return None) / ignore (return input)\n\n\nReturns\nstr\n\nstr - province abbreviation\n\n\n\n\n\nCode\n# * TEST\nwith pytest.raises(Exception, match=\"Invalid province name\"):\n    province_abbrev(\"FL\", errors=\"raise\")\nassert province_abbrev(\"FL\", errors=\"coerce\") is None\nassert province_abbrev(\"FL\", errors=\"ignore\") == \"FL\"\nwith pytest.raises(Exception, match=\"Invalid `error` arg\"):\n    province_abbrev(\"FL\", errors=\"test\")\n\nassert province_abbrev(\"Ontario\") == \"ON\"\nassert province_abbrev(\"ontario\") == \"ON\"\n\nassert province_abbrev(\"newfoundland\") == \"NL\"\nassert province_abbrev(\"NEWFOUNDLAND AND LABRADOR\") == \"NL\"\n\nassert province_abbrev(\"yukon\") == \"YT\"\nassert province_abbrev(\"YUKON TERRITORY\") == \"YT\"\n\nassert province_abbrev(\"PEI\") == \"PE\"\nassert province_abbrev(\"Prince edward island\") == \"PE\"\n\nassert province_abbrev(\"novascotia\") == \"NS\"\nassert province_abbrev(\"nova scotia\") == \"NS\"",
    "crumbs": [
      "00_core"
    ]
  },
  {
    "objectID": "example.html",
    "href": "example.html",
    "title": "02_example",
    "section": "",
    "text": "Code\n# * DOC\ndf = pd.read_parquet(fp(\"../tests2/fake_dat.parquet\"))\ndf.sample(3)\n\n\n\n\n\n\n\n\n\nid\nfname\nlname\ndob\ndob_verified\nemail\nphone\nstreet\ncity\nprov\n...\n__tbl_rows__type_3\n__tbl_rows__type_4\n__tbl_rows__amt_1\n__tbl_rows__amt_2\n__tbl_rows__amt_3\n__tbl_rows__amt_4\n__tbl_rows__details_1\n__tbl_rows__details_2\n__tbl_rows__details_3\n__tbl_rows__details_4\n\n\n\n\n59\n7200744\nCharles\nBerry\n1947-05-12\nTrue\nashleymoss@example.org\n1-257-860-3230\n8772 Melvin Rest\nKnighttown\nPrince Edward Island\n...\nNone\nNone\n$10,335.39\n$75,474.72\nNone\nNone\nDirectly deposited to your bank account less a...\nSUN LIFE FINANCIAL\\nP.O. BOX 11001 STN CV.\\nDI...\nNone\nNone\n\n\n1\n5266792\nRobert\nHenry\n1996-02-04\nTrue\ngonzalesmegan@example.com\n812-671-2491\n54198 Lambert Isle\nStevensstad\nNunavut\n...\nNone\nNone\n$12,810.41\n$41,319.28\nNone\nNone\nDirectly deposited to your bank account less a...\nTD BANK\\n1211 PROSPECT ST\\nFREDERICTON, NB E3...\nNone\nNone\n\n\n97\n3868703\nScott\nDiaz\n1971-01-14\nTrue\nandersonwilliam@example.net\n555-522-6600\n8543 Jones Rapids Suite 740\nWest Marissaton\nSaskatchewan\n...\nNone\nNone\n$151,917.66\n$476,143.71\nNone\nNone\nDirectly deposited to your bank account less a...\nCIBC\\n10A GAGNIER ST.\\nHAY RIVER, NT X0E 1G1\\n\nNone\nNone\n\n\n\n\n3 rows × 25 columns\n\n\n\n\n\nCode\n# * DOC\ndf[\"dt_send\"] = \"May 31, 2024\"\n\ndf[\"str_full_name\"] = df[\"fname\"].str.strip() + \" \" + df[\"lname\"].str.strip()\ndf[\"country\"] = \"Canada\"\ndf[\"prov\"] = df[\"prov\"].apply(lambda x: mm.province_abbrev(x))\n\naddress_dict = {\n    \"name\": \"str_full_name\",\n    \"street1\": \"street\",\n    \"street2\": \"n/a\",\n    \"street3\": \"n/a\",\n    \"city\": \"city\",\n    \"pc\": \"pc\",\n    \"prov\": \"prov\",\n    \"country\": \"country\",\n}\ndf = mm.add_mailing_details_col(df, address_dict, col_name=\"str_mailing_details\")\n\nfor _ in df[\"str_mailing_details\"].tolist()[:3]:\n    print(_, \"\\n\")\n\n\nHENRY ALVARADO\n91971 WILLIAMS SHOALS\nPORT RICHARD, SK  M6J 1P4\nCANADA \n\nROBERT HENRY\n54198 LAMBERT ISLE\nSTEVENSSTAD, NU  M2M 3L2\nCANADA \n\nJENNIFER ROSS\n10535 BARTLETT HILLS\nMCKNIGHTCHESTER, MB  T8K 6J5\nCANADA \n\n\n\n\n\nCode\n# * DOC\ndf[\"dt_dob\"] = df[\"dob\"].apply(lambda x: mm.date_to_string(x))\ndf[\"bool_dob_verified\"] = df[\"dob_verified\"]\n\ndf[\"bool_some_bool\"] = 0\ndf[\"bool_some_bool\"] = df[\"bool_some_bool\"].apply(lambda x: random.randint(0, 1))\ndf[\"bool_some_bool\"] = df[\"bool_some_bool\"].apply(lambda x: True if x == 1 else False)\n\ndf[\"str_comment\"] = df[\"comment\"]\n\nm = df[\"bool_some_bool\"] == True\ndf.loc[~m, \"_group\"] = \"group1\"\ndf.loc[m, \"_group\"] = \"group2\"\n\ndf.columns = [\n    \"id\",\n    \"fname\",\n    \"lname\",\n    \"dob\",\n    \"dob_verified\",\n    \"email\",\n    \"phone\",\n    \"street\",\n    \"city\",\n    \"prov\",\n    \"pc\",\n    \"comment\",\n    \"amt_total\",\n    \"__tbl1__type_1\",\n    \"__tbl1__type_2\",\n    \"__tbl1__type_3\",\n    \"__tbl1__type_4\",\n    \"__tbl1__amt_1\",\n    \"__tbl1__amt_2\",\n    \"__tbl1__amt_3\",\n    \"__tbl1__amt_4\",\n    \"__tbl1__details_1\",\n    \"__tbl1__details_2\",\n    \"__tbl1__details_3\",\n    \"__tbl1__details_4\",\n    \"dt_send\",\n    \"str_full_name\",\n    \"country\",\n    \"str_mailing_details\",\n    \"dt_dob\",\n    \"bool_dob_verified\",\n    \"bool_some_bool\",\n    \"str_comment\",\n    \"_group\",\n]\n\ndf[\"str_comment\"] = df[\"str_comment\"].apply(lambda x: x + \"\\n\\n\")\n\ndf.to_parquet(\"../tests2/_clean_dat.parquet\")\n\n\n\n\n\nFor tables, the original data would typically look something like this:\n\ndata = {\n    \"id\": [99, 99, 100, 100, 100, 100],\n    \"type\": [\"A\", \"C\", \"A\", \"B\", \"A\", \"B\"],\n    \"amt\": [10, 20, 30, 40, 50, 60],\n}\ndf = pd.DataFrame(data)\ndf\n\n\n\n\n\n\n\n\nid\ntype\namt\n\n\n\n\n0\n99\nA\n10\n\n\n1\n99\nC\n20\n\n\n2\n100\nA\n30\n\n\n3\n100\nB\n40\n\n\n4\n100\nA\n50\n\n\n5\n100\nB\n60\n\n\n\n\n\n\n\nTo get all table rows into one row per id:\n\n\nCode\n# * DOC\ndf[\"num\"] = df.groupby(\"id\").cumcount() + 1\ndf_pivot = df.pivot(index=\"id\", columns=\"num\", values=[\"type\", \"amt\"])\ndf_pivot.columns = [f\"__tbl1__{col[0]}_{col[1]}\" for col in df_pivot.columns]\n# where tbl1 corresponds to name of table in template\ndf_pivot = df_pivot.reset_index().copy()\ndf_pivot  # merge this back into rest of data\n\n\n\n\n\n\n\n\n\nid\n__tbl1__type_1\n__tbl1__type_2\n__tbl1__type_3\n__tbl1__type_4\n__tbl1__amt_1\n__tbl1__amt_2\n__tbl1__amt_3\n__tbl1__amt_4\n\n\n\n\n0\n99\nA\nC\nNaN\nNaN\n10\n20\nNaN\nNaN\n\n\n1\n100\nA\nB\nA\nB\n30\n40\n50\n60\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# * DOC\ndef _create_random_benes(id: str) -&gt; pd.DataFrame:\n    from faker import Faker\n\n    fake = Faker()\n    df = pd.DataFrame(columns=[\"id\", \"name\", \"pct\"])\n\n    num_benes = random.randint(1, 4)\n\n    for i in range(num_benes):\n        df.loc[len(df)] = [id, fake.name(), f\"{round(100/num_benes,2)}%\"]\n\n    return df\n\n\nif REFRESH:\n    df = pd.read_parquet(\"../tests2/clean_dat.parquet\")\n    dfs = []\n    for _id in df[\"id\"].tolist():\n        dfs.append(_create_random_benes(_id))\n    benes = pd.concat(dfs)\n\n    benes[\"num\"] = benes.groupby(\"id\").cumcount() + 1\n    benes_pivot = benes.pivot(index=\"id\", columns=\"num\", values=[\"name\", \"pct\"])\n    benes_pivot.columns = [f\"__tbl2__{col[0]}_{col[1]}\" for col in benes_pivot.columns]\n    benes_pivot = benes_pivot.reset_index().copy()\n\n    tm = pd.merge(df, benes_pivot, \"inner\", \"id\")\n    assert len(tm) == len(df)\n    assert len(tm) == len(benes_pivot)\n\n    tm.to_parquet(\"../tests2/clean_dat2.parquet\")\n\n\n\n\n\nConfig is in yaml format:\n\n\n\nscreenshot.png\n\n\nThe config file is used to specify the data source (currently, only parquet is supported to ensure consistent/persistent data types), groups, and what template(s) each group should use.\n\n\nCode\n# * DOC\ncfg_path = \"../tests2/sample_cfg.yml\"\ncfg = yaml_helper(cfg_path)\npprint(cfg)\n\n\n{'data': 'C:\\\\Users\\\\ronal\\\\Desktop\\\\mail_merge\\\\tests2\\\\clean_dat2.parquet',\n 'groups': [{'group1': ['C:\\\\Users\\\\ronal\\\\Desktop\\\\mail_merge\\\\tests2\\\\tpls\\\\sample_tpl.docx',\n                        'C:\\\\Users\\\\ronal\\\\Desktop\\\\mail_merge\\\\tests2\\\\tpls\\\\sample_tpl2.docx']},\n            {'group2': ['C:\\\\Users\\\\ronal\\\\Desktop\\\\mail_merge\\\\tests2\\\\tpls\\\\sample_tpl.docx']}]}\n\n\n\n\nCode\n# * DOC\nif REFRESH:\n    mmm.merge(\n        cfg_path=\"../tests2/sample_cfg.yml\",\n        id_col=\"id\",\n        group_col=\"_group\",\n        _tbls=[\"tbl1\", \"tbl2\"],\n        _test=True,\n        _zip=True,\n    )\n\n\nSample result in /tests2/res_2024...zip\nSample templates used in /tests2/tpls/"
  },
  {
    "objectID": "example.html#loadclean",
    "href": "example.html#loadclean",
    "title": "02_example",
    "section": "",
    "text": "Code\n# * DOC\ndf = pd.read_parquet(fp(\"../tests2/fake_dat.parquet\"))\ndf.sample(3)\n\n\n\n\n\n\n\n\n\nid\nfname\nlname\ndob\ndob_verified\nemail\nphone\nstreet\ncity\nprov\n...\n__tbl_rows__type_3\n__tbl_rows__type_4\n__tbl_rows__amt_1\n__tbl_rows__amt_2\n__tbl_rows__amt_3\n__tbl_rows__amt_4\n__tbl_rows__details_1\n__tbl_rows__details_2\n__tbl_rows__details_3\n__tbl_rows__details_4\n\n\n\n\n59\n7200744\nCharles\nBerry\n1947-05-12\nTrue\nashleymoss@example.org\n1-257-860-3230\n8772 Melvin Rest\nKnighttown\nPrince Edward Island\n...\nNone\nNone\n$10,335.39\n$75,474.72\nNone\nNone\nDirectly deposited to your bank account less a...\nSUN LIFE FINANCIAL\\nP.O. BOX 11001 STN CV.\\nDI...\nNone\nNone\n\n\n1\n5266792\nRobert\nHenry\n1996-02-04\nTrue\ngonzalesmegan@example.com\n812-671-2491\n54198 Lambert Isle\nStevensstad\nNunavut\n...\nNone\nNone\n$12,810.41\n$41,319.28\nNone\nNone\nDirectly deposited to your bank account less a...\nTD BANK\\n1211 PROSPECT ST\\nFREDERICTON, NB E3...\nNone\nNone\n\n\n97\n3868703\nScott\nDiaz\n1971-01-14\nTrue\nandersonwilliam@example.net\n555-522-6600\n8543 Jones Rapids Suite 740\nWest Marissaton\nSaskatchewan\n...\nNone\nNone\n$151,917.66\n$476,143.71\nNone\nNone\nDirectly deposited to your bank account less a...\nCIBC\\n10A GAGNIER ST.\\nHAY RIVER, NT X0E 1G1\\n\nNone\nNone\n\n\n\n\n3 rows × 25 columns\n\n\n\n\n\nCode\n# * DOC\ndf[\"dt_send\"] = \"May 31, 2024\"\n\ndf[\"str_full_name\"] = df[\"fname\"].str.strip() + \" \" + df[\"lname\"].str.strip()\ndf[\"country\"] = \"Canada\"\ndf[\"prov\"] = df[\"prov\"].apply(lambda x: mm.province_abbrev(x))\n\naddress_dict = {\n    \"name\": \"str_full_name\",\n    \"street1\": \"street\",\n    \"street2\": \"n/a\",\n    \"street3\": \"n/a\",\n    \"city\": \"city\",\n    \"pc\": \"pc\",\n    \"prov\": \"prov\",\n    \"country\": \"country\",\n}\ndf = mm.add_mailing_details_col(df, address_dict, col_name=\"str_mailing_details\")\n\nfor _ in df[\"str_mailing_details\"].tolist()[:3]:\n    print(_, \"\\n\")\n\n\nHENRY ALVARADO\n91971 WILLIAMS SHOALS\nPORT RICHARD, SK  M6J 1P4\nCANADA \n\nROBERT HENRY\n54198 LAMBERT ISLE\nSTEVENSSTAD, NU  M2M 3L2\nCANADA \n\nJENNIFER ROSS\n10535 BARTLETT HILLS\nMCKNIGHTCHESTER, MB  T8K 6J5\nCANADA \n\n\n\n\n\nCode\n# * DOC\ndf[\"dt_dob\"] = df[\"dob\"].apply(lambda x: mm.date_to_string(x))\ndf[\"bool_dob_verified\"] = df[\"dob_verified\"]\n\ndf[\"bool_some_bool\"] = 0\ndf[\"bool_some_bool\"] = df[\"bool_some_bool\"].apply(lambda x: random.randint(0, 1))\ndf[\"bool_some_bool\"] = df[\"bool_some_bool\"].apply(lambda x: True if x == 1 else False)\n\ndf[\"str_comment\"] = df[\"comment\"]\n\nm = df[\"bool_some_bool\"] == True\ndf.loc[~m, \"_group\"] = \"group1\"\ndf.loc[m, \"_group\"] = \"group2\"\n\ndf.columns = [\n    \"id\",\n    \"fname\",\n    \"lname\",\n    \"dob\",\n    \"dob_verified\",\n    \"email\",\n    \"phone\",\n    \"street\",\n    \"city\",\n    \"prov\",\n    \"pc\",\n    \"comment\",\n    \"amt_total\",\n    \"__tbl1__type_1\",\n    \"__tbl1__type_2\",\n    \"__tbl1__type_3\",\n    \"__tbl1__type_4\",\n    \"__tbl1__amt_1\",\n    \"__tbl1__amt_2\",\n    \"__tbl1__amt_3\",\n    \"__tbl1__amt_4\",\n    \"__tbl1__details_1\",\n    \"__tbl1__details_2\",\n    \"__tbl1__details_3\",\n    \"__tbl1__details_4\",\n    \"dt_send\",\n    \"str_full_name\",\n    \"country\",\n    \"str_mailing_details\",\n    \"dt_dob\",\n    \"bool_dob_verified\",\n    \"bool_some_bool\",\n    \"str_comment\",\n    \"_group\",\n]\n\ndf[\"str_comment\"] = df[\"str_comment\"].apply(lambda x: x + \"\\n\\n\")\n\ndf.to_parquet(\"../tests2/_clean_dat.parquet\")"
  },
  {
    "objectID": "example.html#note-on-tables",
    "href": "example.html#note-on-tables",
    "title": "02_example",
    "section": "",
    "text": "For tables, the original data would typically look something like this:\n\ndata = {\n    \"id\": [99, 99, 100, 100, 100, 100],\n    \"type\": [\"A\", \"C\", \"A\", \"B\", \"A\", \"B\"],\n    \"amt\": [10, 20, 30, 40, 50, 60],\n}\ndf = pd.DataFrame(data)\ndf\n\n\n\n\n\n\n\n\nid\ntype\namt\n\n\n\n\n0\n99\nA\n10\n\n\n1\n99\nC\n20\n\n\n2\n100\nA\n30\n\n\n3\n100\nB\n40\n\n\n4\n100\nA\n50\n\n\n5\n100\nB\n60\n\n\n\n\n\n\n\nTo get all table rows into one row per id:\n\n\nCode\n# * DOC\ndf[\"num\"] = df.groupby(\"id\").cumcount() + 1\ndf_pivot = df.pivot(index=\"id\", columns=\"num\", values=[\"type\", \"amt\"])\ndf_pivot.columns = [f\"__tbl1__{col[0]}_{col[1]}\" for col in df_pivot.columns]\n# where tbl1 corresponds to name of table in template\ndf_pivot = df_pivot.reset_index().copy()\ndf_pivot  # merge this back into rest of data\n\n\n\n\n\n\n\n\n\nid\n__tbl1__type_1\n__tbl1__type_2\n__tbl1__type_3\n__tbl1__type_4\n__tbl1__amt_1\n__tbl1__amt_2\n__tbl1__amt_3\n__tbl1__amt_4\n\n\n\n\n0\n99\nA\nC\nNaN\nNaN\n10\n20\nNaN\nNaN\n\n\n1\n100\nA\nB\nA\nB\n30\n40\n50\n60"
  },
  {
    "objectID": "example.html#test-2-tables",
    "href": "example.html#test-2-tables",
    "title": "02_example",
    "section": "",
    "text": "Code\n# * DOC\ndef _create_random_benes(id: str) -&gt; pd.DataFrame:\n    from faker import Faker\n\n    fake = Faker()\n    df = pd.DataFrame(columns=[\"id\", \"name\", \"pct\"])\n\n    num_benes = random.randint(1, 4)\n\n    for i in range(num_benes):\n        df.loc[len(df)] = [id, fake.name(), f\"{round(100/num_benes,2)}%\"]\n\n    return df\n\n\nif REFRESH:\n    df = pd.read_parquet(\"../tests2/clean_dat.parquet\")\n    dfs = []\n    for _id in df[\"id\"].tolist():\n        dfs.append(_create_random_benes(_id))\n    benes = pd.concat(dfs)\n\n    benes[\"num\"] = benes.groupby(\"id\").cumcount() + 1\n    benes_pivot = benes.pivot(index=\"id\", columns=\"num\", values=[\"name\", \"pct\"])\n    benes_pivot.columns = [f\"__tbl2__{col[0]}_{col[1]}\" for col in benes_pivot.columns]\n    benes_pivot = benes_pivot.reset_index().copy()\n\n    tm = pd.merge(df, benes_pivot, \"inner\", \"id\")\n    assert len(tm) == len(df)\n    assert len(tm) == len(benes_pivot)\n\n    tm.to_parquet(\"../tests2/clean_dat2.parquet\")"
  },
  {
    "objectID": "example.html#run-merge",
    "href": "example.html#run-merge",
    "title": "02_example",
    "section": "",
    "text": "Config is in yaml format:\n\n\n\nscreenshot.png\n\n\nThe config file is used to specify the data source (currently, only parquet is supported to ensure consistent/persistent data types), groups, and what template(s) each group should use.\n\n\nCode\n# * DOC\ncfg_path = \"../tests2/sample_cfg.yml\"\ncfg = yaml_helper(cfg_path)\npprint(cfg)\n\n\n{'data': 'C:\\\\Users\\\\ronal\\\\Desktop\\\\mail_merge\\\\tests2\\\\clean_dat2.parquet',\n 'groups': [{'group1': ['C:\\\\Users\\\\ronal\\\\Desktop\\\\mail_merge\\\\tests2\\\\tpls\\\\sample_tpl.docx',\n                        'C:\\\\Users\\\\ronal\\\\Desktop\\\\mail_merge\\\\tests2\\\\tpls\\\\sample_tpl2.docx']},\n            {'group2': ['C:\\\\Users\\\\ronal\\\\Desktop\\\\mail_merge\\\\tests2\\\\tpls\\\\sample_tpl.docx']}]}\n\n\n\n\nCode\n# * DOC\nif REFRESH:\n    mmm.merge(\n        cfg_path=\"../tests2/sample_cfg.yml\",\n        id_col=\"id\",\n        group_col=\"_group\",\n        _tbls=[\"tbl1\", \"tbl2\"],\n        _test=True,\n        _zip=True,\n    )\n\n\nSample result in /tests2/res_2024...zip\nSample templates used in /tests2/tpls/"
  }
]