[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mail_merge",
    "section": "",
    "text": "At TELUS Health / LifeWorks, I have successfully executed over a dozen mail merges, many of which had thousands of recipients, a wide variety of templates, tight deadlines, and constant changes to both templates and data.\nWith a natural inclination for process efficiency, I used Python scripts to streamline the process. For the sake of organization, maintainability, and documentation, I have bundled commonly used functions from those scripts into a single package.\nI have also tested, with great results, using docxtpl for the actual merge itself as the built-in MS Word function proved inconsistent and unreliable, especially for larger merges and complex templates.\nThis package allows for effortless running and re-running of merges with manual steps kept to a minimum. This is particularly useful when there are frequent changes to the templates and/or data, and when there are many different groups requiring different combinations of templates.\nDocumentation",
    "crumbs": [
      "mail_merge"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "00_core",
    "section": "",
    "text": "setupLogger (name:str='log', serialize:bool=False)\n\nadd handler attached to &lt;name&gt;.log @ trace level and up\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\nlog\nstr\n\n\nserialize\nbool\nFalse\nbool\n\n\nReturns\nNone\n\n\n\n\n\n\n\n\n\n\n loadSerializedLog (log_fp:str, incl_full_record:bool=False,\n                    incl_unix_ts:bool=False)\n\n-&gt; pd.DataFrame\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlog_fp\nstr\n\nstr\n\n\nincl_full_record\nbool\nFalse\nbool\n\n\nincl_unix_ts\nbool\nFalse\nbool\n\n\nReturns\nDataFrame\n\npd.DataFrame\n\n\n\n\n\n\n\n\n fp (_path:str='', ambiguous_err:bool=True)\n\nFor referencing relative file paths in dev env. Assumes core is always one level down from project root directory.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\n_path\nstr\n\nstr - eg. \"../dat/some_file.csv\" == \"&lt;project_root&gt;/dat/some_file.csv&gt;\"\n\n\nambiguous_err\nbool\nTrue\nbool - if True, will raise exception if path is ambiguous when running docs generation vs dev env\n\n\nReturns\nstr\n\nstr\n\n\n\n\n\n\n\n\n yaml_helper (fpath:str='./config.yaml', mode:str='r',\n              data:Optional[dict]=None)\n\nHelper function to read, write, append to files in yaml format. Checks for duplicate keys if reading or appending.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfpath\nstr\n./config.yaml\nstr\n\n\nmode\nstr\nr\nstr - r / a / w\n\n\ndata\nOptional\nNone\ncannot be None if writing or appending\n\n\nReturns\ndict\n\ndict - data if reading, {‘r’: 0} if writing/appending",
    "crumbs": [
      "00_core"
    ]
  },
  {
    "objectID": "core.html#numbers",
    "href": "core.html#numbers",
    "title": "00_core",
    "section": "numbers",
    "text": "numbers\n\n\nFormatOptions\n\n FormatOptions (_format:bool=True, prefix:str='', suffix:str='',\n                comma_str:str=',', decimal_str:str='.',\n                pad_zeroes_at_end:bool=True,\n                return_int_if_possible:bool=False,\n                accounting_notation:bool=False)\n\nOptions for numerical formatting. Supports most locale conventions / currency formatting:\n_format: bool = True  # True returns str, False returns float\nprefix: str = \"\"\nsuffix: str = \"\"\ncomma_str: str = \",\"\ndecimal_str: str = \".\"\npad_zeroes_at_end: bool = True\nreturn_int_if_possible: bool = False\naccounting_notation: bool = False  # negative numbers in parentheses\n\n\n\nfix_round\n\n fix_round (num:float|int, position:int=0)\n\nPython’s built-in round function can return unexpected results. See https://docs.python.org/3/library/functions.html#round. This function returns the same result as the Excel ROUND function.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnum\nfloat | int\n\nfloat | int\n\n\nposition\nint\n0\nint\n\n\nReturns\nfloat\n\nfloat\n\n\n\n\n\nTests\nwith pytest.raises(Exception, match=\"Invalid input\"):\n    fix_round(\"test\", 123)  # type: ignore\n\nassert round(23.335, 2) == 23.34\nassert round(23.345, 2) == 23.34\nassert fix_round(23.345, 2) == 23.35\n\nassert round(-23.345, 2) == -23.34\nassert fix_round(-23.345, 2) == -23.35\n\nassert fix_round(1, 2) == 1\nassert isinstance((fix_round(1, 2)), float)\n\nassert fix_round(1.0, 2) == 1\nassert isinstance((fix_round(1.0, 2)), float)\n\nassert round(6789.2342335, 6) == 6789.234234\nassert round(6789.2342345, 6) == 6789.234234\nassert fix_round(6789.2342345, 6) == 6789.234235\n\nassert round(-6789.2342345, 6) == -6789.234234\nassert fix_round(-6789.2342345, 6) == -6789.234235\n\nassert fix_round(0.0, 2) == 0.0\nassert fix_round(-0.0, 2) == 0.0\n\n\n\n\n\nround_and_format\n\n round_and_format (num:float|int, position:int,\n                   format_opts:__main__.FormatOptions)\n\n-&gt; str | float | None\n\n\n\n\nType\nDetails\n\n\n\n\nnum\nfloat | int\nfloat | int\n\n\nposition\nint\nint\n\n\nformat_opts\nFormatOptions\nFormatOptions\n\n\nReturns\nstr | float | None\nstr | float | None\n\n\n\n\nround_and_format(\n    -9123.9999, 1, FormatOptions(return_int_if_possible=True, comma_str=\"\")\n)\n\n'-9124'\n\n\n\nround_and_format(\n    -9123.56345, 2, FormatOptions(prefix=\"$\", accounting_notation=True)\n)  # https://ifrscommunity.com/forum/viewtopic.php?p=4931&sid=53703b358d2485c3b7eb07f00128b20d#p4931\n\n'$(9,123.56)'\n\n\n\nround_and_format(\n    -5.56123345, 2, FormatOptions(comma_str=\"\", suffix=\"%\", accounting_notation=True)\n)  # https://ifrscommunity.com/forum/viewtopic.php?p=4931&sid=53703b358d2485c3b7eb07f00128b20d#p4931\n\n'(5.56)%'\n\n\n\nround_and_format(9123.445, 2, FormatOptions(prefix=\"$\", comma_str=\"\"))\n\n'$9123.45'\n\n\n\nround_and_format(9123.445, 2, FormatOptions(prefix=\"$\"))\n\n'$9,123.45'\n\n\n\nround_and_format(9123.445, 2, FormatOptions(suffix=\"$\", comma_str=\" \", decimal_str=\",\"))\n\n'9 123,45$'\n\n\n\nround_and_format(9123.445, 2, FormatOptions(suffix=\"$\", comma_str=\".\", decimal_str=\",\"))\n\n'9.123,45$'\n\n\n\n\nTests\nassert round_and_format(123.445, 2, FormatOptions()) == \"123.45\"\nassert round_and_format(9123.445, 2, FormatOptions()) == \"9,123.45\"\nassert round_and_format(2123.445, 2, FormatOptions(comma_str=\"\")) == \"2123.45\"\nassert (\n    round_and_format(123.445, 4, FormatOptions(comma_str=\"\", pad_zeroes_at_end=True))\n    == \"123.4450\"\n)\nassert round_and_format(-2342.475, 2, FormatOptions()) == \"-2,342.48\"\n\nassert (\n    round_and_format(2342.999, 0, FormatOptions(return_int_if_possible=True)) == \"2,343\"\n)\nassert (\n    round_and_format(2342.999, 0, FormatOptions(return_int_if_possible=False))\n    == \"2,343.0\"\n)\nassert (\n    round_and_format(\n        2342.999, 0, FormatOptions(return_int_if_possible=False, comma_str=\"\")\n    )\n    == \"2343.0\"\n)\nassert round_and_format(2342.999, 0, FormatOptions(comma_str=\"\")) == \"2343.0\"\n\nassert (\n    round_and_format(2342.999, 1, FormatOptions(return_int_if_possible=True)) == \"2,343\"\n)\nassert (\n    round_and_format(\n        2342.999, 1, FormatOptions(return_int_if_possible=True, comma_str=\"\")\n    )\n    == \"2343\"\n)\nassert (\n    round_and_format(2342.999, 1, FormatOptions(return_int_if_possible=False))\n    == \"2,343.0\"\n)\n\nassert round_and_format(0.0, 0, FormatOptions()) == \"0.0\"\n\nx = round_and_format(9123.445, 2, FormatOptions(_format=False))\nassert isinstance(x, float)\n\n\n\n\ntestInvalidInputs\ndefault_opts = FormatOptions()\nwith pytest.raises(Exception, match=\"invalid\"):\n    round_and_format(\"0\", 0, default_opts)  # type: ignore\nwith pytest.raises(Exception, match=\"invalid\"):\n    round_and_format(\"abc\", 0, default_opts)  # type: ignore\n\n\n\n\ntestNullInput\nx = round_and_format(None, 0, default_opts)  # type: ignore\nassert x is None\n\nx = round_and_format(np.nan, 0, default_opts)  # type: ignore\nassert x is None\n\nx = round_and_format(pd.NaT, 0, default_opts)  # type: ignore\nassert x is None\n\n\n\n\ntestAccountingNotation\nassert (\n    round_and_format(\n        -9123.56345, 2, FormatOptions(prefix=\"$\", accounting_notation=True)\n    )\n    == \"$(9,123.56)\"\n)\nassert (\n    round_and_format(9123.56345, 2, FormatOptions(prefix=\"$\", accounting_notation=True))\n    == \"$9,123.56\"\n)\nassert (\n    round_and_format(\n        -5.56123345,\n        2,\n        FormatOptions(comma_str=\"\", suffix=\"%\", accounting_notation=True),\n    )\n    == \"(5.56)%\"\n)\nassert (\n    round_and_format(\n        5.56123345,\n        2,\n        FormatOptions(comma_str=\" \", suffix=\"%\", accounting_notation=True),\n    )\n    == \"5.56%\"\n)",
    "crumbs": [
      "00_core"
    ]
  },
  {
    "objectID": "core.html#dates",
    "href": "core.html#dates",
    "title": "00_core",
    "section": "dates",
    "text": "dates\n\n\ndate_to_string\n\n date_to_string\n                 (t_val:pandas._libs.tslibs.timestamps.Timestamp|datetime.\n                 datetime, long:bool=True, period:bool=False,\n                 french:bool=False)\n\n\n\nTests\nx = datetime(2024, 3, 19, 16, 39, 2, 126548)\nassert date_to_string(x) == \"March 19, 2024\"\nassert date_to_string(x, long=False) == \"Mar 19, 2024\"\nassert date_to_string(x, period=True, long=False) == \"Mar. 19, 2024\"\n\nx = pd.to_datetime(\"19-mar-2024\")\nassert date_to_string(x) == \"March 19, 2024\"\nassert date_to_string(x, long=False) == \"Mar 19, 2024\"\nassert date_to_string(x, period=True, long=False) == \"Mar. 19, 2024\"\n\n\n\n\ntestFrench\nx = datetime(1920, 12, 1, 0, 0)\nassert date_to_string(x, french=True) == \"1 décembre 1920\"\nassert date_to_string(x, french=True, long=False, period=True) == \"1 déc. 1920\"\nassert date_to_string(x, french=True, long=False, period=False) == \"1 déc 1920\"\n\n\n\n\ntestInvalidAndNullInput\nwith pytest.raises(Exception, match=\"invalid input\"):\n    date_to_string(\"19-mar-2024\")  # type: ignore\n\nwith pytest.raises(Exception, match=\"invalid input\"):\n    date_to_string(123)  # type: ignore\n\nx = date_to_string(None)  # type: ignore\nassert x is None\n\nx = date_to_string(pd.NaT)  # type: ignore\nassert x is None\n\nx = date_to_string(np.nan)  # type: ignore\nassert x is None\n\n\n\n\n\nconvertExcelNumericDates\n\n convertExcelNumericDates (numerical_date:float|int)\n\n-&gt; pd.Timestamp\n\n\n\n\nType\nDetails\n\n\n\n\nnumerical_date\nfloat | int\nfloat | int - eg. 45292.25\n\n\nReturns\nTimestamp\npd.Timestamp\n\n\n\n\n\nTests\nassert convertExcelNumericDates(0) == datetime(1899, 12, 31, 0, 0)\nassert convertExcelNumericDates(2) == datetime(1900, 1, 2, 0, 0)\nassert convertExcelNumericDates(45292) == datetime(2024, 1, 1, 0, 0)\nassert convertExcelNumericDates(45292.0) == datetime(2024, 1, 1, 0, 0)\nassert convertExcelNumericDates(45292.25) == datetime(2024, 1, 1, 6, 0)\n\nassert convertExcelNumericDates(0) == pd.to_datetime(datetime(1899, 12, 31, 0, 0))\nassert convertExcelNumericDates(2) == pd.to_datetime(datetime(1900, 1, 2, 0, 0))\nassert convertExcelNumericDates(45292) == pd.to_datetime(datetime(2024, 1, 1, 0, 0))\nassert convertExcelNumericDates(45292.0) == pd.to_datetime(datetime(2024, 1, 1, 0, 0))\nassert convertExcelNumericDates(45292.25) == pd.to_datetime(datetime(2024, 1, 1, 6, 0))\n\nx = convertExcelNumericDates(45292)\nassert isinstance(x, pd.Timestamp)\n\n\n\n\n\nconvert_yyyymmdd\n\n convert_yyyymmdd (date_str:str)\n\n…\n\n\n\n\nType\nDetails\n\n\n\n\ndate_str\nstr\nstr - eg. 19810123\n\n\nReturns\nTimestamp\npd.Timestamp\n\n\n\n\n\nTests\nassert convert_yyyymmdd(\"19120124\") == pd.Timestamp(\"1912-01-24 00:00:00\")",
    "crumbs": [
      "00_core"
    ]
  },
  {
    "objectID": "core.html#address",
    "href": "core.html#address",
    "title": "00_core",
    "section": "address",
    "text": "address\n\n\nadd_mailing_details_col\n\n add_mailing_details_col (df:pandas.core.frame.DataFrame,\n                          address_dict:dict,\n                          col_name:str='str_mailing_details')\n\n*Adds column to dataframe w/ full mailing details in upper case:\n&lt;full name&gt;\n&lt;street lines (up to 3)&gt;\n&lt;city, province  postal code&gt; - handles various combinations of missing data in case of foreign addresses\n&lt;country&gt;\nIf there’s a c/o line, moves it to 2nd line.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\npd.DataFrame\n\n\naddress_dict\ndict\n\ndict - see docs for example\n\n\ncol_name\nstr\nstr_mailing_details\nstr - name of column that will be added\n\n\nReturns\nDataFrame\n\npd.DataFrame\n\n\n\n\n\ntestAddMailingDetailsCol1\naddress_dict = {\n    \"name\": \"str_full_name2\",\n    \"street1\": \"Address-1\",\n    \"street2\": \"Address-2\",\n    \"street3\": \"Address-3\",\n    \"city\": \"Address-4\",\n    \"pc\": \"Postal Code\",\n    \"prov\": \"Province\",\n    \"country\": \"Current Address.Country\",\n}\n\ncompare_df = pd.read_parquet(fp(\"../tests/addMailingDetailsCol/dat.parquet\"))\ndf = _prep_data0()  # where `Address-3` column is present\nres = add_mailing_details_col(df, address_dict)\nassert res[\"str_mailing_details\"].tolist() == compare_df[\"str_mailing_details\"].tolist()\n\n\n\n\ntestAddMailingDetailsCol2\ndf = _prep_data1()  # where `Address-3` column is not present\nres = add_mailing_details_col(df, address_dict)\nassert res[\"str_mailing_details\"].tolist() == compare_df[\"str_mailing_details\"].tolist()\n\n\nExample\n\ndf = pd.read_excel(\"../tests/for_docs/fake_data.xlsx\")\ndf\n\n\n\n\n\n\n\n\nid\nfname\nlname\ndob\ndob_verified\nemail\nphone\n_full_name\nstreet1\nstreet2\ncity\nprovince\npostal_code\ncountry\ncomment\namt\nrand_int\n\n\n\n\n0\n5790492\nHenry\nAlvarado\n1940-01-10\nTrue\nmbrown@example.org\n(465) 529-2322\nHenry Alvarado\n91971 Williams Shoals\nc/o James Smith\nPort Richard\nSK\nM6J 1P4\nCanada\nTenetur hic eaque praesentium.\n74068.20\n4582\n\n\n1\n5266792\nRobert\nHenry\n1996-02-04\nTrue\ngonzalesmegan@example.com\n812-671-2491\nRobert Henry\n54198 Lambert Isle\nUnit 5\nStevensstad\nNU\nM2M 3L2\nCanada\nVoluptatibus fugit nam repellendus nemo repell...\n324.62\n5486\n\n\n2\n3735642\nJennifer\nRoss\n2004-04-27\nTrue\nhernandezjill@example.org\n1-156-761-3895\nJennifer Ross\n10535 Bartlett Hills\nNaN\nMcknightchester\nMB\nT8K 6J5\nCanada\nTemporibus eaque quis dignissimos reiciendis d...\n9770.60\n9002\n\n\n\n\n\n\n\n\n# Sample `address_dict`, where values are column names in the data. Max 3 columns for street column.\naddress_dict = {\n    \"name\": \"_full_name\",\n    \"street1\": \"street1\",\n    \"street2\": \"street2\",\n    \"street3\": \"n/a\",\n    \"city\": \"city\",\n    \"prov\": \"province\",\n    \"pc\": \"postal_code\",\n    \"country\": \"country\",\n}\n\nres = add_mailing_details_col(df, address_dict, \"str_mailing_details\")\nfor r in res[\"str_mailing_details\"].tolist():\n    print(r)\n    print(\"\")\n\nHENRY ALVARADO\nC/O JAMES SMITH\n91971 WILLIAMS SHOALS\nPORT RICHARD, SK  M6J 1P4\nCANADA\n\nROBERT HENRY\n54198 LAMBERT ISLE\nUNIT 5\nSTEVENSSTAD, NU  M2M 3L2\nCANADA\n\nJENNIFER ROSS\n10535 BARTLETT HILLS\nMCKNIGHTCHESTER, MB  T8K 6J5\nCANADA\n\n\n\n\n\n\nabbreviateProvince\n\n abbreviateProvince (province_name:str, errors:str='raise')\n\n…\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nprovince_name\nstr\n\nfull name of province\n\n\nerrors\nstr\nraise\n- raise- coerce (if no match, return None)- ignore (return input)\n\n\nReturns\nstr | None\n\nprovince abbreviation or None\n\n\n\n\n\ntestAbbrevProvince\nwith pytest.raises(Exception, match=\"Invalid province name\"):\n    abbreviateProvince(\"FL\", errors=\"raise\")\nassert abbreviateProvince(\"FL\", errors=\"coerce\") is None\nassert abbreviateProvince(\"FL\", errors=\"ignore\") == \"FL\"\nwith pytest.raises(Exception, match=\"Invalid `error` arg\"):\n    abbreviateProvince(\"FL\", errors=\"test\")\n\nassert abbreviateProvince(\"Ontario\") == \"ON\"\nassert abbreviateProvince(\"ontario\") == \"ON\"\n\nassert abbreviateProvince(\"newfoundland\") == \"NL\"\nassert abbreviateProvince(\"NEWFOUNDLAND AND LABRADOR\") == \"NL\"\n\nassert abbreviateProvince(\"yukon\") == \"YT\"\nassert abbreviateProvince(\"YUKON TERRITORY\") == \"YT\"\n\nassert abbreviateProvince(\"PEI\") == \"PE\"\nassert abbreviateProvince(\"Prince edward island\") == \"PE\"\n\nassert abbreviateProvince(\"novascotia\") == \"NS\"\nassert abbreviateProvince(\"nova scotia\") == \"NS\"",
    "crumbs": [
      "00_core"
    ]
  },
  {
    "objectID": "merge.html",
    "href": "merge.html",
    "title": "01_merge",
    "section": "",
    "text": "createSampleCfg (_fn:str='sample_cfg.yml', _overwrite:bool=False)\n\nCreate sample cfg file in cwd\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\n_fn\nstr\nsample_cfg.yml\nstr\n\n\n_overwrite\nbool\nFalse\nbool\n\n\nReturns\nNone\n\n\n\n\n\nThe config file uses YAML format for easy editing. Here you specify the data / template filepaths, as well as which groups require which templates. For example:\ndata: 'C:\\...\\tests\\example\\clean_dat2.parquet'\nid_col: 'id'\ngroup_col: '_group'\nmulti_line_cols:  # optional\n  - 'str_mailing_details'\ntables:  # optional\n  - 'tbl1'\n  - 'tbl2'\ngroups: \n- group1:\n  - 'C:\\...\\tests\\example\\tpl\\sample_tpl.docx'\n  - 'C:\\...\\tests\\example\\tpl\\sample_tpl2.docx'\n- group2:\n  - 'C:\\...\\tests\\example\\tpl\\sample_tpl.docx'\nThis is particularly useful when you have many groups, each requiring different (combinations of) templates.",
    "crumbs": [
      "01_merge"
    ]
  },
  {
    "objectID": "merge.html#payment-details-table",
    "href": "merge.html#payment-details-table",
    "title": "01_merge",
    "section": "payment details table",
    "text": "payment details table\n\ntbl_dat = pd.read_parquet(\"../tests/example/table_data.parquet\")\ntbl_dat.head(5)\n\n\n\n\n\n\n\n\nid\namt\ntype\ndetails\n\n\n\n\n0\n1065999\n$26,308.80\nCash\nDirectly deposited to your bank account less a...\n\n\n0\n1065999\n$82,571.66\nLocked-in Transfer\nBANK OF MONTREAL\\n33 MAIN ST.\\nPORT AUX BASQUE...\n\n\n1\n1257262\n$3,403.46\nCash\nDirectly deposited to your bank account less a...\n\n\n2\n1307164\n$10,200.83\nCash\nDirectly deposited to your bank account less a...\n\n\n2\n1307164\n$62,598.72\nLocked-in Transfer\nCANADA LIFE\\n255 DUFFERIN AVE\\nT424\\nLONDON, O...\n\n\n\n\n\n\n\n\npmt_tbl = pivotTblData(tbl_dat, \"tbl1\")\npmt_tbl.head(3)\n\n\n\n\n\n\n\n\nid\n__tbl1__amt_1\n__tbl1__amt_2\n__tbl1__amt_3\n__tbl1__amt_4\n__tbl1__type_1\n__tbl1__type_2\n__tbl1__type_3\n__tbl1__type_4\n__tbl1__details_1\n__tbl1__details_2\n__tbl1__details_3\n__tbl1__details_4\n\n\n\n\n0\n1065999\n$26,308.80\n$82,571.66\nNaN\nNaN\nCash\nLocked-in Transfer\nNaN\nNaN\nDirectly deposited to your bank account less a...\nBANK OF MONTREAL\\n33 MAIN ST.\\nPORT AUX BASQUE...\nNaN\nNaN\n\n\n1\n1257262\n$3,403.46\nNaN\nNaN\nNaN\nCash\nNaN\nNaN\nNaN\nDirectly deposited to your bank account less a...\nNaN\nNaN\nNaN\n\n\n2\n1307164\n$10,200.83\n$62,598.72\nNaN\nNaN\nCash\nLocked-in Transfer\nNaN\nNaN\nDirectly deposited to your bank account less a...\nCANADA LIFE\\n255 DUFFERIN AVE\\nT424\\nLONDON, O...\nNaN\nNaN\n\n\n\n\n\n\n\n\ntm = pd.merge(df, pmt_tbl, on=\"id\", how=\"inner\")\nassert len(tm) == len(df)\nassert len(tm) == len(pmt_tbl)",
    "crumbs": [
      "01_merge"
    ]
  },
  {
    "objectID": "merge.html#clean-data",
    "href": "merge.html#clean-data",
    "title": "01_merge",
    "section": "clean data",
    "text": "clean data\n\ndf = tm.copy()\ndf[\"dt_send\"] = \"March 31, 2025\"\n\ndf[\"str_full_name\"] = df[\"fname\"].str.strip() + \" \" + df[\"lname\"].str.strip()\ndf[\"country\"] = \"Canada\"\ndf[\"prov\"] = df[\"prov\"].apply(lambda x: mm.abbreviateProvince(x))\n\naddress_dict = {\n    \"name\": \"str_full_name\",\n    \"street1\": \"street\",\n    \"street2\": \"n/a\",\n    \"street3\": \"n/a\",\n    \"city\": \"city\",\n    \"pc\": \"pc\",\n    \"prov\": \"prov\",\n    \"country\": \"country\",\n}\ndf = mm.add_mailing_details_col(df, address_dict, col_name=\"str_mailing_details\")\n\ndf[\"str_comment\"] = df[\"comment\"].apply(lambda x: x + \"\\n\\n\")\n\ndf[\"dt_dob\"] = df[\"dob\"].apply(lambda x: mm.date_to_string(x))\n\ndel df[\"dob_verified\"]  # for example\nfor c in [\"bool_some_bool\", \"bool_dob_verified\"]:\n    df[c] = 0\n    df[c] = df[c].apply(lambda x: random.randint(0, 1))\n    df[c] = df[c].apply(lambda x: True if x == 1 else False)\n\ndf[\"_group\"] = \"group1\"\nm = df[\"bool_some_bool\"] == True\ndf.loc[m, \"_group\"] = \"group2\"\n\nm = df[\"__tbl1__details_3\"].notna()\ndf.loc[m, \"_group\"] = \"group3\"\n\ndf.to_parquet(\"../tests/example/clean_dat.parquet\")",
    "crumbs": [
      "01_merge"
    ]
  },
  {
    "objectID": "merge.html#add-another-table",
    "href": "merge.html#add-another-table",
    "title": "01_merge",
    "section": "add another table",
    "text": "add another table\n\nbenes = pd.read_parquet(\"../tests/example/fake_benes.parquet\")\nbenes.head(8)\n\n\n\n\n\n\n\n\nid\nname\npct\n\n\n\n\n0\n5790492\nMichael Wall\n50.0%\n\n\n1\n5790492\nRoy Baker\n50.0%\n\n\n2\n5266792\nTerry Robles\n50.0%\n\n\n3\n5266792\nStephanie Scott\n50.0%\n\n\n4\n3735642\nKeith Dougherty\n25.0%\n\n\n5\n3735642\nGary Anderson\n25.0%\n\n\n6\n3735642\nAaron Little\n25.0%\n\n\n7\n3735642\nChristopher Park\n25.0%\n\n\n\n\n\n\n\n\nbenes = pivotTblData(benes, \"tbl2\").copy()\nbenes.head(3)\n\n\n\n\n\n\n\n\nid\n__tbl2__name_1\n__tbl2__name_2\n__tbl2__name_3\n__tbl2__name_4\n__tbl2__pct_1\n__tbl2__pct_2\n__tbl2__pct_3\n__tbl2__pct_4\n\n\n\n\n0\n1065999\nJames Reynolds\nLisa Shields\nNicolas Moore\nNaN\n33.33%\n33.33%\n33.33%\nNaN\n\n\n1\n1257262\nStephanie Donaldson\nTanya Hernandez\nJose Thornton\nNaN\n33.33%\n33.33%\n33.33%\nNaN\n\n\n2\n1307164\nNatalie Allen\nNaN\nNaN\nNaN\n100.0%\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\ndf = pd.read_parquet(fp(\"../tests/example/clean_dat.parquet\"))\n\ntm = pd.merge(df, benes, on=\"id\", how=\"inner\")\nassert len(tm) == len(df)\nassert len(tm) == len(benes)\n\ntm.to_parquet((\"../tests/example/clean_dat2.parquet\"))",
    "crumbs": [
      "01_merge"
    ]
  },
  {
    "objectID": "merge.html#merge-2",
    "href": "merge.html#merge-2",
    "title": "01_merge",
    "section": "merge",
    "text": "merge\nConfig file would look something like this:\ndata: 'C:\\...\\tests\\example\\clean_dat2.parquet'\nid_col: 'id'\ngroup_col: '_group'\nmulti_line_cols: \n  - 'str_mailing_details'\ntables:\n  - 'tbl1'\n  - 'tbl2'\ngroups: \n- group1:\n  - 'C:\\...\\tests\\example\\tpl\\sample_tpl.docx'\n  - 'C:\\...\\tests\\example\\tpl\\sample_tpl_with_benes.docx'\n- group2:\n  - 'C:\\...\\tests\\example\\tpl\\sample_tpl.docx'\n- group3:\n  - 'C:\\...\\tests\\example\\tpl\\sample_tpl_more_payments.docx'\n\nmerge(\n    cfg_path=\"../tests/example/sample_cfg.yml\",\n    _test=3,\n)\n\n100%|██████████| 3/3 [00:00&lt;00:00,  3.04it/s]\n100%|██████████| 3/3 [00:01&lt;00:00,  2.67it/s]\n100%|██████████| 3/3 [00:01&lt;00:00,  2.95it/s]\n100%|██████████| 3/3 [00:01&lt;00:00,  2.95it/s]\n\n\nAll files used in this example, including the resulting outputs, can be found here.",
    "crumbs": [
      "01_merge"
    ]
  }
]